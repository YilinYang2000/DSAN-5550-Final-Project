{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data processing procedure outlined aims to handle missing data and outliers for datasets related to wind farms and solar stations, each with a specified nominal capacity. The process ensures the integrity and usability of the data for subsequent analysis or predictive modeling tasks. Each dataset undergoes systematic treatment to identify and rectify missing values, followed by the detection and handling of outliers, which could distort subsequent analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning Steps:\n",
    "1. Load the Datasets:\n",
    "\n",
    "Load data from multiple Excel files for wind farms and solar stations, dropping the first row in each file which presumably contains template or incorrect data.\n",
    "\n",
    "2. Define Cleaning Function (clean_and_handle_outliers):\n",
    "\n",
    "Replace Placeholder Values: Substitute placeholder and incorrect values ('0.001', '−99', '–', 'NA', '--', '<NULL>', '') with NaN (Not a Number).\n",
    "Correct Wind Speed Values: Ensure that wind speed values are non-negative by replacing any negative values with NaN.\n",
    "Handle Temperature Values: Filter out unreasonable temperature readings (less than -100°C or greater than 100°C) by replacing them with NaN.\n",
    "Interpolate Numeric Columns: Perform linear interpolation on numeric columns to fill in missing data, applying both forward and backward limits.\n",
    "Fill Remaining Missing Data: Use forward fill and backward fill methods to handle any remaining missing values.\n",
    "Handle Outliers: Identify outliers using the Interquartile Range (IQR) method and cap them at 1.5 times the IQR above the third quartile and below the first quartile.\n",
    "\n",
    "3. Apply the Cleaning Function:\n",
    "\n",
    "Process each dataset individually based on whether they are wind farm (WF) or solar station (SS) datasets, using appropriate columns for wind speed and temperature.\n",
    "Output Processed Datasets:\n",
    "\n",
    "4. Save each cleaned and processed dataset back into an Excel file within a specified directory for processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "# Load datasets\n",
    "datasets = {\n",
    "    'WF_site1': pd.read_excel('../renewable_energy_data/data_original/wind_farms/Wind farm site 1 (Nominal capacity-99MW).xlsx').drop(index=0),\n",
    "    'WF_site2': pd.read_excel('../renewable_energy_data/data_original/wind_farms/Wind farm site 2 (Nominal capacity-200MW).xlsx').drop(index=0),\n",
    "    'WF_site3': pd.read_excel('../renewable_energy_data/data_original/wind_farms/Wind farm site 3 (Nominal capacity-99MW).xlsx').drop(index=0),\n",
    "    'WF_site4': pd.read_excel('../renewable_energy_data/data_original/wind_farms/Wind farm site 4 (Nominal capacity-66MW).xlsx').drop(index=0),\n",
    "    'WF_site5': pd.read_excel('../renewable_energy_data/data_original/wind_farms/Wind farm site 5 (Nominal capacity-36MW).xlsx').drop(index=0),\n",
    "    'WF_site6': pd.read_excel('../renewable_energy_data/data_original/wind_farms/Wind farm site 6 (Nominal capacity-96MW).xlsx').drop(index=0),\n",
    "    'SS_site1': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 1 (Nominal capacity-50MW).xlsx').drop(index=0),\n",
    "    'SS_site2': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 2 (Nominal capacity-130MW).xlsx').drop(index=0),\n",
    "    'SS_site3': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 3 (Nominal capacity-30MW).xlsx').drop(index=0),\n",
    "    'SS_site4': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 4 (Nominal capacity-130MW).xlsx').drop(index=0),\n",
    "    'SS_site5': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 5 (Nominal capacity-110MW).xlsx').drop(index=0),\n",
    "    'SS_site6': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 6 (Nominal capacity-35MW).xlsx').drop(index=0),\n",
    "    'SS_site7': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 7 (Nominal capacity-30MW).xlsx').drop(index=0),\n",
    "    'SS_site8': pd.read_excel('../renewable_energy_data/data_original/solar_stations/Solar station site 8 (Nominal capacity-30MW).xlsx').drop(index=0)\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing WF_site1...\n",
      "Finished processing WF_site1. Shape: (70175, 13)\n",
      "Processing WF_site2...\n",
      "Finished processing WF_site2. Shape: (70175, 13)\n",
      "Processing WF_site3...\n",
      "Finished processing WF_site3. Shape: (70175, 13)\n",
      "Processing WF_site4...\n",
      "Finished processing WF_site4. Shape: (70175, 13)\n",
      "Processing WF_site5...\n",
      "Finished processing WF_site5. Shape: (70175, 13)\n",
      "Processing WF_site6...\n",
      "Finished processing WF_site6. Shape: (70175, 13)\n",
      "Processing SS_site1...\n",
      "Finished processing SS_site1. Shape: (70175, 8)\n",
      "Processing SS_site2...\n",
      "Finished processing SS_site2. Shape: (70175, 8)\n",
      "Processing SS_site3...\n",
      "Finished processing SS_site3. Shape: (52607, 8)\n",
      "Processing SS_site4...\n",
      "Finished processing SS_site4. Shape: (70175, 8)\n",
      "Processing SS_site5...\n",
      "Finished processing SS_site5. Shape: (70175, 8)\n",
      "Processing SS_site6...\n",
      "Finished processing SS_site6. Shape: (70175, 8)\n",
      "Processing SS_site7...\n",
      "Finished processing SS_site7. Shape: (70175, 8)\n",
      "Processing SS_site8...\n",
      "Finished processing SS_site8. Shape: (69407, 8)\n"
     ]
    }
   ],
   "source": [
    "def clean_and_handle_outliers(df, wind_speed_cols, temp_col):\n",
    "    # Replace placeholder and incorrect values with NaN\n",
    "    placeholders = ['0.001', '−99', '–', 'NA', '--', '<NULL>', '']\n",
    "    df.replace(placeholders, np.nan, inplace=True)\n",
    "\n",
    "    # Correct negative wind speed values\n",
    "    for col in wind_speed_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: np.nan if x < 0 else x)\n",
    "\n",
    "    # Handle unreasonable air temperature values\n",
    "    if temp_col in df.columns:\n",
    "        df[temp_col] = df[temp_col].apply(lambda x: np.nan if x < -100 or x > 100 else x)\n",
    "\n",
    "    # Interpolate missing data for numerical columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Forward fill and backward fill remaining missing data\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Adjust outlier handling to ignore zero values that are placeholders\n",
    "    # and not convert valid non-zero readings to NaNs\n",
    "    for col in numeric_cols:\n",
    "        if col in wind_speed_cols:\n",
    "            # Only apply outlier capping to non-zero values\n",
    "            non_zero_values = df[col] != 0\n",
    "            Q1 = df.loc[non_zero_values, col].quantile(0.25)\n",
    "            Q3 = df.loc[non_zero_values, col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Cap outliers\n",
    "            df.loc[non_zero_values, col] = np.where(df.loc[non_zero_values, col] < lower_bound, lower_bound, df.loc[non_zero_values, col])\n",
    "            df.loc[non_zero_values, col] = np.where(df.loc[non_zero_values, col] > upper_bound, upper_bound, df.loc[non_zero_values, col])\n",
    "        else:\n",
    "            # Handle outliers using the interquartile range for other numerical columns\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            # Cap outliers\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "\n",
    "    return df\n",
    "# Now apply the cleaning and outlier handling function to each dataset\n",
    "processed_datasets = {}\n",
    "for key, dataset in datasets.items():\n",
    "    print(f\"Processing {key}...\")\n",
    "    if 'WF' in key:  # For Wind farm datasets\n",
    "        processed_datasets[key] = clean_and_handle_outliers(dataset, wind_farm_cols, temperature_col)\n",
    "    elif 'SS' in key:  # For Solar station datasets\n",
    "        processed_datasets[key] = clean_and_handle_outliers(dataset, solar_station_cols, temperature_col)\n",
    "    else:\n",
    "        # Apply a general cleaning if the dataset key doesn't specify WF or SS\n",
    "        processed_datasets[key] = clean_and_handle_outliers(dataset, wind_farm_cols + solar_station_cols, temperature_col)\n",
    "    print(f\"Finished processing {key}. Shape: {processed_datasets[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data for WF_site1 to ../renewable_energy_data/data_processed/WF_site1_processed.xlsx\n",
      "Saved processed data for WF_site2 to ../renewable_energy_data/data_processed/WF_site2_processed.xlsx\n",
      "Saved processed data for WF_site3 to ../renewable_energy_data/data_processed/WF_site3_processed.xlsx\n",
      "Saved processed data for WF_site4 to ../renewable_energy_data/data_processed/WF_site4_processed.xlsx\n",
      "Saved processed data for WF_site5 to ../renewable_energy_data/data_processed/WF_site5_processed.xlsx\n",
      "Saved processed data for WF_site6 to ../renewable_energy_data/data_processed/WF_site6_processed.xlsx\n",
      "Saved processed data for SS_site1 to ../renewable_energy_data/data_processed/SS_site1_processed.xlsx\n",
      "Saved processed data for SS_site2 to ../renewable_energy_data/data_processed/SS_site2_processed.xlsx\n",
      "Saved processed data for SS_site3 to ../renewable_energy_data/data_processed/SS_site3_processed.xlsx\n",
      "Saved processed data for SS_site4 to ../renewable_energy_data/data_processed/SS_site4_processed.xlsx\n",
      "Saved processed data for SS_site5 to ../renewable_energy_data/data_processed/SS_site5_processed.xlsx\n",
      "Saved processed data for SS_site6 to ../renewable_energy_data/data_processed/SS_site6_processed.xlsx\n",
      "Saved processed data for SS_site7 to ../renewable_energy_data/data_processed/SS_site7_processed.xlsx\n",
      "Saved processed data for SS_site8 to ../renewable_energy_data/data_processed/SS_site8_processed.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory to save output files\n",
    "output_directory = '../renewable_energy_data/data_processed'\n",
    "os.makedirs(output_directory, exist_ok=True)  # This creates the directory if it doesn't exist\n",
    "\n",
    "# Process and output each dataset\n",
    "for key, dataset in processed_datasets.items():\n",
    "    output_path = os.path.join(output_directory, f'{key}_processed.xlsx')\n",
    "    dataset.to_excel(output_path, index=False)\n",
    "    print(f\"Saved processed data for {key} to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
